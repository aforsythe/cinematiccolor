\chapter{Introduction}

\section{Intended audience}

This document is intended for professionals involved in the capture, production and finishing of film, animation, and games, with a particular focus on the computer graphics artists and software developers responsible for visual effects, animation and games color management. A familiarity with computer graphics fundamentals is assumed. As advanced color imaging techniques, like wide color gamut and high-dynamic range capture, processing and display, become more widely used outside of the entertainment space, we expect that this paper will also be relevant to professionals beyond the intended audience. A familiarity with color science and color management is not.

\section{How to read this document}

The paper is broken into this Introduction, sections on Color Science and Workflow and an Appendix. The ordering of the content should introduce a reader new to the subject to the concepts and terminology needed to understand successive topics. For those focused on specific production workflows or challenges, it is reasonable to follow from the Introduction to Workflow, referring to Color Science, as needed. The Appendix provides more applied examples and explanation where it was deemed appropriate.

\section{The goal}

Professionals in the motion picture, visual effects, animation, and games industries encounter color management challenges which are not covered in either traditional color science textbooks or online resources, leaving digital artists and computer graphics developers to fend for themselves. Best practices are too often maintained through tribal knowledge: passed along by word of mouth, user forums, or scripts copied between facilities. This document’s goal is to provide a better mechanism for communicating this information.

The paper also outlines the color pipeline challenges in modern feature film, visual effects, animation and games production, from on-set capture to the computer graphics pipeline to digital intermediate (DI) grading and final display. It presents techniques and best practices currently in use at major production facilities and notes areas that need further development and standardization.

One note to begin with: Color pipelines are not static nor is there a single best approach. They grow and evolve with the constraints of each project. This paper intends to present color measurement, processing, and pipelines in enough generality that the reader will be able to address the specific needs of their productions, even if they are not described explicitly in the text. It is unlikely that this paper will address the exact requirements of any given production in whole.

\section{Converging approaches}

Figure 1. A high-level element breakdown for live-action, mixed live action, animation and games shots. Each image is generated using a roughly consistent set of stages and processing steps. The succession of image states is as follows: 1) Camera image, in camera-native color space 2) Ungraded camera image or renderer output in an ungraded working color space 3) Image with generic grade 4) Final graded image for primary output with composited background and foreground elements and 5) graded image for an alternate output like PQ or DCDM. The terms used here are defined later in this document.
Images are © Geoff Boyle  © 2018 MARVEL, © Disney/Pixar,  © Disney 2018. Imagery from Battlefield V courtesy of Electronic Arts Inc, © 2018 Electronic Arts Inc. All rights reserved.

Since the first version of this document, there has been a convergence of approaches across cinematography, visual effects, animation, games, finishing, and grading. Shared challenges in the evolution of display and capture technology: a shift from photochemical to digital image capture, widely available wide-gamut high-dynamic range (HDR) displays, advances in rendering and image generation research and the increased integration of different production departments have driven this harmonization. Each production will define a slightly different overall color pipeline, but most discussion, debate, and variation boils down to choices made around the transforms and formats used. Image and color data with specific meaning, referring to scene or display intensities, and transforms, with specific expectations for input and output format, are concepts that are used remarkably consistently across on-set capture, visual effects, games, finishing, grading and software and hardware color processing pipelines.	 

Figure 1 above shows a consistent set of image states leading towards the final frame for live action, live-action with integrated visual effects, fully synthetic visual effects images, animated features, and games.

\section{A general model of color processing}

Digital color management follows a clear general path tightly coupled with digital imaging. The high-level diagram below covers this path, from reflectance, image formation, storage and processing to display.

The ‘Computer Graphics’ box hides a complex pipeline that largely mimics the physical processes that precede it in this diagram, with the goals of creating content that will blend seamlessly with the captured image. Key: Purple - physical light, Blue - stored light, Green - Synthetic light, Orange - perceived light

While there are many imaging considerations along the full imaging pipeline, such as spatial and temporal considerations, this discussion restricted itself to the propagation and transformation of color in the imaging pipeline.

The simplest example of the digital color pipeline for cinema is exemplified by a digital camera, covering the full imaging pipeline from lens to sensor to the display on the back of the camera. Even this simplest case involves processing and transforms that are a microcosm of more complex pipelines. From this example, it is possible to expand to cover pipelines and workflows that have processing steps in-camera, on-set, in a scanning house, with editors, in a renderer, visual effects, animation and games teams, colorists, distribution processing, cinemas, streaming services and everywhere in between. In this section, the paper will present simple models for thinking about color processing and understanding which aspects are important in each phase of production.

In the simple case mentioned above, an image captured by a digital camera and displayed on the screen on the back of the camera, there are a series of states and transforms to consider:
Light reflected off a surface, into camera’s lens and onto an image sensor
Sensor photosite values encoded and stored in memory
A transform to combine adjacent Red, Green and Blue photosites into single pixel values
A “working space” image in memory
A transform to remap the intensities of the combined pixels for display
A “displayable” image ready to be sent to the display hardware
The display hardware showing the image


Optical diagram of a typical mirrorless digital camera.
Unknown. (n.d.). DSLR Optical Diagram. Retrieved October 14, 2018, from https://www.dpreview.com/forums/post/61693925

The aspects of the example above that will show up repeatedly throughout this document are:

Input, Working, Output: The example includes the stages that are common to most modern color pipelines, namely an Input, Capture or Generated image state, a Working image state used for editing and production and an Output image state used for display. There may be other steps along the way, but virtually all modern color pipeline designs contain these three distinct states. The Input image for a visual effects or animated feature or game may be the product of a renderer.

Scene-referred, Output-referred images: The sensor image in Step 3 represents the intensity of light in the scene, filtered through the camera’s lens and specific red, green and blue filters over each sensor photosite. The “working space” image from Step 5 also represents the intensity of light in the scene, but may be device-independent, at least slightly abstracted from the camera sensor and processing hardware. After being transformed for display, the image in Step 6 has values representing the activations necessary for each of the target display’s pixels.

Transforms - Input, Output, Look: Going between each image state is a transformation that has a specific, meaningful effect. The most widely used transforms will typically include a remapping of intensities and some degree of remapping of the color gamut: the underlying meaning of the red, green and blue of each pixel. There are many more exotic transforms, and often a number of these simpler transforms are concatenated. Transforms going from Input to the Working space are usually strictly defined based on the capabilities of the capture device and the attributes of the working space. Transforms from the Working space to the Output space usually combine an element of artistry, commonly referred to as “the Look”, with an explicit mapping based on the capabilities of the output device. Later sections of the document contain many examples of transforms used in practice.

Staged Processing: The process to go from light hitting the sensor to a display emitting light is defined by a specific, staged processing pipeline. Transforms take color from one image state to the next, constrained by the processing needs of each successive stage and the limitations and capabilities of the capture, processing and display hardware. Images may be written to disk or passed along an IO line representing the state of color at any of the points in the processing chain, as different applications or departments within production may be the source or the destination for the data. 

Meaning and Placement - Understanding how to work with an image or color data set is more natural when you can be clear about what the data is supposed to represent and where it lives in the production or product’s processing chain. These two elements, meaning and placement, provide the context needed to apply transformations and make aesthetic judgements in production.

\subsection{ACES}

The Academy Color Encoding System (ACES) is a color management system that embodied the general model of color processing described above. It codifies and standardizes many of the elements described in the Workflow section with an eye towards addressing many of the difficulties listed in the Challenges section below. The basic system diagram for ACES is presented below.


ACES system diagram

This diagram contains scene-referred imagery, transforms converting from one state or color space to the next, working spaces, output-referred imagery and an ordered, staged processing pipeline.

ACES is one of many ways to define a color pipeline, but it presents a nice embodiment of the general model of color processing presented above, mirrored in most of the examples discussed in this paper. ACES will be referenced throughout this document because it is open, well documented, widely available and has been used successfully in a wide variety of projects of all types and complexities. It provides a great starting point for exploration. This should not be taken as a suggestion that ACES is the only or necessarily the best option. Decisions about which color transforms and spaces to use should be base on the requirements and constraints of a given project.

\section{Color management challenges in film, visual effects, animation and games}

While the approaches in different industries and departments have converged, there are still many challenges when speaking about and working with color. They are: 
					
Multiple Requirements: It is difficult to lump on-set capture, visual effects, animation, games, grading and finishing into a single bucket, as each discipline has potentially different color pipeline goals and constraints. For example, in visual effects production, one of the golden rules is that image regions absent of visual effects should not be modified in any way. This places a constraint on color pipelines: that color conversions applied to the photography must be perfectly invertible. Animation and games have their own unique set of requirements, such as high-fidelity handling of saturated portions of the color gamut along with large areas of smooth color gradients. On-set capture teams are focused on a shot to shot consistency, capturing as much dynamic range with as little noise as possible. Grading teams have to deliver a set of final images that retain the intended look and feel of the production and take maximum advantage of the output device(s), standard dynamic range (SDR) and high-dynamic range (HDR). Thus, color pipelines must keep track of the “big picture” priorities but are often tailored to specific productions and groups.
						
Varying Terminology: Working with color in a single production setting can be a challenge. An additional complicating factor is the abundance of overlapping and overloaded terminology for describing color and operations on color. As more parts of the production pipeline interact, from on-set capture to visual effects to grading and mastering, the history, and constraints that defined how each group thinks and talks about color come in contact when they may not have previously. Terms like grade, HDR, linear, brightness, gamma, light, look development or LUT may have clear, but different, meanings in two adjacent production groups. On top of overloaded terms, many acronyms in use add a level of perceived complexity to what would otherwise be an easily understood process. The Glossary in the Appendix is our attempt to address some of this overloading of terms.

Various Color Philosophies: There are many schools of thought on how to best manage color in digital motion-picture production. There is far more variation in motion-picture color management than in desktop publishing. Some facilities render in high-dynamic range (HDR) color spaces. Other facilities prefer to render in low-dynamic range (LDR). Some facilities rely on the output display characteristics, like gamma, as the primary tool in crafting the final image appearance. Others do not. It is challenging to provide standardized workflows and toolsets when the current practice has such variation.
												
Multiple Inputs & Outputs: In live-action productions, imagery is often acquired using a multitude of input capture devices: multiple digital motion picture cameras from different vendors, still cameras, “action cameras,” specialized HDR panorama cameras, LIDAR scanners, and it is desired to merge these different sources seamlessly. On the output side, the final image deliverables are tailored to distinct viewing environments: digital theatrical presentation, film theatrical presentation, SDR and HDR home theater, television broadcast, augmented and virtual reality devices. The rapid evolution of HDR display’s brightness and color gamut standards poses particular challenges for content creation and grading. Each of these outputs has different color considerations. Furthermore, artists often work on desktop displays with “office” viewing conditions, yet require a high-fidelity preview of the final appearance.
				
Complex Software Ecosystem: Another challenge is that the majority of the motion picture, visual effects, animation and games productions use many software tools: on-set monitoring, LUT boxes, image viewers, 2D and 3D painting applications, compositing applications, lighting tools, editing and grading suite, media generation and transcoding software  and so on. Although it is imperative that artists work in a color managed pipeline across multiple applications, color support is quite varied between software vendors. Ideally, all software tools that interchange images, perform color conversions or display images should be color managed consistently. This is not the case. Each production and facility has to understand the capabilities and behavior of the applications they elect to use as part of their pipeline design. The issue of interchange takes on an even more complex angle when you consider that multiple facilities often share image assets on a single production. Color management practices and technologies that encourage high-fidelity, consistent interchange are sorely needed.
						
Protecting Imagery: On-set capture, visual effects, and animation are not the end of the line for image processing. Digital intermediate (DI) Grading is a powerful tool for crafting the final appearance of a motion picture that may substantially impact the appearance of the final image. It is, therefore, a necessity for on-set capture and post-production color pipelines to protect the fidelity of the captured and rendered image, even under drastic color corrections. It is very likely that late stage color corrections will reveal underlying problems in the captured or computer-generated imagery if digital intermediate is not considered earlier in production. Artifacts not visible in production because of the viewing conditions or introduced by changes made in post-production might be very obvious in HDR or at 2 stops less exposure. The eventual application of compression is also a consideration.
Future-Proofing Required: Display technology is continually evolving, most recently with high resolution (UltraHD), wide color gamut (Rec. 2020) and higher dynamic range (Rec. 2100). For large productions, it is very prudent to take all steps possible to future-proof the computer-generated (CG) imagery so that visual effects (VFX) elements can be repurposed and do not need to be recreated when the next generation of display technology appears. It is good practice to work and archive at the source resolution. Color space, bit depth, and dynamic range should also be protected. These requirements can be very demanding of storage, bandwidth and processing power in modern times, often resulting in the use of compression algorithms to ease the strain. Some of these may be visually lossless yet still impact the color pipeline in the later stages.